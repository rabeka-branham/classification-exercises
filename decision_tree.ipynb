{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19cb39b1-db9e-4a0a-8566-4efbd966bc58",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "## Using the titanic data, in your classification-exercises repository, create a notebook, `decision_tree.ipynb` where you will do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de72c5e4-2ef0-42d5-88c4-51717639473a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import acquire\n",
    "import prepare\n",
    "import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bc2aeb8-26d8-44d2-881f-7bfcf2148309",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists - reading CSV file\n"
     ]
    }
   ],
   "source": [
    "train,\\\n",
    "validate,\\\n",
    "test = prepare.split_data(\n",
    "    prepare.prep_titanic(\n",
    "    acquire.get_titanic_data()),'survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3313be01-cd12-41ed-9912-f118f3493d31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train,validate,test = model.preprocess_titanic(train,validate,test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42948d5a-90f1-4ea0-8cd8-ce7c397b9625",
   "metadata": {},
   "source": [
    "### 1. What is your baseline prediction? What is your baseline accuracy? *remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). When you make those predictions, what is your accuracy? This is your baseline accuracy.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acb37e6a-dbff-4a4f-9297-2c2d89bf1cc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'survived':train.survived,'prediction':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0695897-991a-4e36-b61e-f1941dab8033",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6161048689138576"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.survived == df.prediction).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea70d449-1228-4776-a606-e589581a28f8",
   "metadata": {},
   "source": [
    "### 2. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "651b60dd-0011-415b-9e7c-99e6b72c4022",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = train.drop(columns='survived')\n",
    "y_train = train.survived\n",
    "\n",
    "X_val = validate.drop(columns='survived')\n",
    "y_val = validate.survived\n",
    "\n",
    "X_test = test.drop(columns='survived')\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5464f006-9006-41f8-ad01-c6310bbd8c6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36ece152-9758-42b5-8d69-8a74091a744a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dt = dt.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b12a360c-3313-4ab7-ae43-6b4b870c8a57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = dt.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ebda9b7-38e3-4263-ad11-570a23820929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>534 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual  prediction\n",
       "580       1           1\n",
       "140       0           1\n",
       "747       1           1\n",
       "615       1           1\n",
       "132       0           0\n",
       "..      ...         ...\n",
       "461       0           0\n",
       "344       0           0\n",
       "513       1           1\n",
       "467       0           0\n",
       "530       1           1\n",
       "\n",
       "[534 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'actual': train.survived,'prediction':y_pred})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fec3a4-a140-4f63-a9dd-a33856275e0e",
   "metadata": {},
   "source": [
    "### 3. Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "42baa800-d505-427a-abb9-44f4befa881d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8220973782771536"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68fc0587-e14b-4eff-84db-1a7ed8ff2644",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>312</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     1    0\n",
       "1  312   17\n",
       "0   78  127"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = (y_train.unique())\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f233aaf-6df2-4c6f-9982-402b0f39ba98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.95      0.87       329\n",
      "           1       0.88      0.62      0.73       205\n",
      "\n",
      "    accuracy                           0.82       534\n",
      "   macro avg       0.84      0.78      0.80       534\n",
      "weighted avg       0.83      0.82      0.81       534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a211e1-db94-480f-8302-f8c8c5a9f71e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4. Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bdf1b82-8425-45ca-bd71-2571d5d30fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.95      0.87       329\n",
      "           1       0.88      0.62      0.73       205\n",
      "\n",
      "    accuracy                           0.82       534\n",
      "   macro avg       0.84      0.78      0.80       534\n",
      "weighted avg       0.83      0.82      0.81       534\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf19f6b-e4ee-494f-8e00-532654b48493",
   "metadata": {},
   "source": [
    "### 5. Run through steps 2-4 using a different `max_depth` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db6a0ab-e2d4-4ab2-a3f7-77a4aa4254aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ca55a59-ce99-4a4e-a88d-a1784ccf84d1",
   "metadata": {},
   "source": [
    "### 6. Which model performs better on your in-sample data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644a8918-a6c2-4c06-846b-3b0bb1fda637",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e8edb5a-c24f-4af8-a1ab-b25d8b81d2ce",
   "metadata": {},
   "source": [
    "### 7. Which model performs best on your out-of-sample data, the `validate` set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b7d378-7ebb-4f1a-8a67-9679b2f43bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9074b531-0492-49fa-a6da-633e692eed1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae91191-382a-46e6-9f9e-6290ef4ccc60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2c7111-1176-4efc-b67e-156e6f7cc3cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e595be7-5883-41d5-b433-48083ab0f629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf5848b-012e-4a57-b318-25dacc78df43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0679630b-f2f6-4a24-b973-570a384ba5f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
