{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2900667c-b068-4258-89c9-8f0526d2f0d4",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae91943-e50c-4957-9dfb-7842941ea5f3",
   "metadata": {},
   "source": [
    "## Do these exercises in a notebook called `modeling.ipynb` first, then transfer the final functions to the model.py file.\n",
    "\n",
    "## This work should all be saved in your local `classification-exercises` repo. Add, commit, and push your changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a25f4aed-4b27-4fd8-9e50-bd4f9928af0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import acquire\n",
    "import prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7e3784-8653-4ccc-9f91-154acabbcc23",
   "metadata": {},
   "source": [
    "### <ins>**Using the Titanic dataset**</ins>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6f11c9-c1e2-4c81-87c8-14079de24b82",
   "metadata": {},
   "source": [
    "**1. Use the function defined in `acquire.py` to load the Titanic data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e61baa-a0a8-44a7-bf99-022d8c032a81",
   "metadata": {},
   "source": [
    "**2. Use the function defined in `prepare.py` to prepare the titanic data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c4718ed-2b38-4d26-bd41-4e118d8dc47a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File does not exist - creating CSV file\n"
     ]
    }
   ],
   "source": [
    "titanic_train,\\\n",
    "titanic_validate,\\\n",
    "titanic_test = prepare.split_data(\n",
    "    prepare.prep_titanic(\n",
    "    acquire.get_titanic_data()),'survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "daafb41a-dde5-41c5-a5c3-12826c91d1d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((534, 8), (178, 8), (179, 8))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_train.shape, titanic_validate.shape, titanic_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "668b576e-ff47-4ef8-baa2-7bb36400ca04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15.2458</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>59.4000</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>534 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived pclass     sex  sibsp  parch     fare  embark_town  alone\n",
       "580         1      2  female      1      1  30.0000  Southampton      0\n",
       "140         0      3  female      0      2  15.2458    Cherbourg      0\n",
       "747         1      2  female      0      0  13.0000  Southampton      1\n",
       "615         1      2  female      1      2  65.0000  Southampton      0\n",
       "132         0      3  female      1      0  14.5000  Southampton      0\n",
       "..        ...    ...     ...    ...    ...      ...          ...    ...\n",
       "461         0      3    male      0      0   8.0500  Southampton      1\n",
       "344         0      2    male      0      0  13.0000  Southampton      1\n",
       "513         1      1  female      1      0  59.4000    Cherbourg      0\n",
       "467         0      1    male      0      0  26.5500  Southampton      1\n",
       "530         1      2  female      1      1  26.0000  Southampton      0\n",
       "\n",
       "[534 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da146efc-39d4-499d-8b57-5b0d0386fb48",
   "metadata": {},
   "source": [
    "**3. Encode the categorical columns on train dataset. Create dummy variables of the categorical columns and concatenate them onto the dataframe. Remove the columns they are replacing. Repeat on validate and test.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb7d30e-2ce7-42d5-b706-27db564cff87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_titanic.loc[:,'is_female'] = df_titanic.sex.map({'male': 0, 'female': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4f1cd0-e30d-486c-91da-da771f2c95a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981bad83-bc92-4eed-9249-f4b9e93ad2ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_titanic[['is_queenstown', 'is_southampton']] = pd.get_dummies(df_titanic.embark_town,drop_first=True).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d351fd-85fd-4229-aab4-9e24cdce51a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_titanic = df_titanic.drop(columns=['sex','embark_town'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dbb9ca-b448-4e79-9dbe-720949b322b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abd5c6f-21b2-41e9-af62-758dda6eb303",
   "metadata": {},
   "source": [
    "**4. Create a function named `preprocess_titanic` that accepts the train, validate, and test titanic data, and returns the dataframes ready for modeling.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9683166-4a38-458b-af47-584bbafe4f2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_titanic(train_df, validate_df, test_df):\n",
    "    train.pclass = train.pclass.astype(int)\n",
    "    train.loc[:,'is_female'] = train.sex.map({'male': 0, 'female': 1})\n",
    "    train[['is_queenstown', 'is_southampton']] = pd.get_dummies(train.embark_town,drop_first=True).astype(int)\n",
    "    train = train.drop(columns=['sex','embark_town'])\n",
    "    \n",
    "    validate.pclass = validate.pclass.astype(int)\n",
    "    validate.loc[:,'is_female'] = validate.sex.map({'male': 0, 'female': 1})\n",
    "    validate[['is_queenstown', 'is_southampton']] = pd.get_dummies(validate.embark_town,drop_first=True).astype(int)\n",
    "    validate = validate.drop(columns=['sex','embark_town'])\n",
    "    \n",
    "    test.pclass = test.pclass.astype(int)\n",
    "    test.loc[:,'is_female'] = test.sex.map({'male': 0, 'female': 1})\n",
    "    test[['is_queenstown', 'is_southampton']] = pd.get_dummies(test.embark_town,drop_first=True).astype(int)\n",
    "    test = test.drop(columns=['sex','embark_town'])\n",
    "    \n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fe7235-40fe-4ea9-accc-c6c16bbd8d0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train,validate,test = preprocess_titanic(train,validate,test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9d1aee-f410-4743-a0a0-07d35a36567e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <ins>**Using the Telco dataset**</ins>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6b926d-6208-4b79-982a-5c789e1d2fc6",
   "metadata": {
    "tags": []
   },
   "source": [
    "**1. Use the function defined in acquire.py to load the Telco data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d1988d-53eb-4773-9b8e-134922ed7193",
   "metadata": {},
   "source": [
    "**2. Use the function defined in prepare.py to prepare the Telco data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7ade04e-3b52-4db1-9829-4855a1d2c694",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists - reading CSV file\n"
     ]
    }
   ],
   "source": [
    "telco_train,\\\n",
    "telco_validate,\\\n",
    "telco_test = prepare.split_data(\n",
    "    prepare.prep_telco(\n",
    "        acquire.get_telco_data()),'churn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "831998f4-de81-413c-be6e-c76231febb7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4225, 20), (1409, 20), (1409, 20))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telco_train.shape, telco_validate.shape, telco_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a41b30a-c5b7-412e-83ee-432d1f059cbd",
   "metadata": {},
   "source": [
    "**3. Encode the categorical columns on train.**\n",
    "\n",
    "> **a. Encode at least one column using .replace**\n",
    "\n",
    "> **b. Encode at least one column using .map**\n",
    "\n",
    "> **c. Encode the rest of the columns by creating dummy variables and concatenating them onto the dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e5239e-6e65-4047-bc8b-6e6595c17544",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train['is_male'] = pd.get_dummies(train.gender,drop_first=True).astype(int)\n",
    "train = train.drop(columns=['gender'])\n",
    "train.insert(0, 'is_male', train.pop('is_male')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fafba3-23bf-4147-b66b-908d9424c758",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.loc[:,'internet_service'] = np.where(train['online_security'] == 'No internet service', 0, 1)\n",
    "train.insert(7, 'internet_service', train.pop('internet_service')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd73a49-5c55-4803-9f96-a3f4585c2f3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yes_no_columns = ['partner', 'dependents', 'phone_service','paperless_billing','churn']\n",
    "\n",
    "for col in train[yes_no_columns]:\n",
    "    train.loc[:,col] = train[col].map({'Yes': 1,'No': 0})\n",
    "    train[col] = train[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3219558f-f58d-43fb-a283-bd56e5720d1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "multi_answer_columns = ['multiple_lines','online_security', 'online_backup',\n",
    "       'device_protection', 'tech_support', 'streaming_tv', 'streaming_movies']\n",
    "\n",
    "for col in train[multi_answer_columns]:\n",
    "    train.loc[:,col] = np.where(train[col] == 'Yes', 1, 0)\n",
    "    train[col] = train[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26082155-38d7-4666-b91c-c3dd704ad8ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train[['one_year_contract','two_year_contract']] = pd.get_dummies(train.contract_type,drop_first=True).astype(int)\n",
    "train = train.drop(columns=['contract_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18e92b7-88cc-41d8-b4b6-7c101457cd99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.internet_service_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b407f46-2954-428b-b4ed-391b931b3cbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train[['dsl','fiber_optic','no_internet']] = pd.get_dummies(train.internet_service_type).astype(int)\n",
    "train = train.drop(columns=['internet_service_type','no_internet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4380df1-42dc-4355-be87-e3d20e7fd5f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train[['pay_credit_card','pay_electronic_check','pay_mailed_check']] = pd.get_dummies(train.payment_type,drop_first=True).astype(int)\n",
    "train = train.drop(columns=['payment_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f7cf8d-dcdb-4b3f-896c-fb34afa64c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa66dd34-7a58-4755-af3a-bb8064e9040a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c89b3c-5eef-456f-b2df-2372da06c496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfd4fbb-7cbf-4616-b579-d86bed00c8af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c794c73-0054-4951-ac35-fd985fa33bbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1853df-b919-4fda-9479-dd1171111fa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f36502c-e96b-4f2b-bb2e-4e368cea59d6",
   "metadata": {},
   "source": [
    "**4. Repeat the same steps on validate and test.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4af961-d551-45e6-bb29-26db39d51a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ad73520-54cb-4145-b1e2-405d50cab8e0",
   "metadata": {},
   "source": [
    "**5. Create a function named prep_telco that accepts the train, validate, and test telco data, and returns the dataframes ready for modeling.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a931693-f7b4-4694-b43a-a4e17f179683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_telco(train,validate,test):\n",
    "    dataframe_set = [train,validate,test]\n",
    "    \n",
    "    for df in dataframe_set:\n",
    "        df['is_male'] = pd.get_dummies(df.gender,drop_first=True).astype(int)\n",
    "        df = df.drop(columns=['gender'])\n",
    "        df.insert(0, 'is_male', train.pop('is_male')) \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
